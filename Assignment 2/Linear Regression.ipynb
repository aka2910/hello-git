{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "charitable-candidate",
   "metadata": {},
   "source": [
    "This assignment is about fitting a Linear Regression Model for the data. To do this assignment you are expected to complete till Week 2 of the prescribed course.\n",
    "Make a folder named \"Assignment 2\", in the same repository that you submitted, and copy this notebook and the dataset to the directory. I won't be guiding you through to make commits, this time you have to decide your checkpoints to do the versioning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collaborative-marble",
   "metadata": {},
   "source": [
    "The below cell has been left to import python modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manufactured-ancient",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "directed-teach",
   "metadata": {},
   "source": [
    "Let's get started, open the file and import the two columns (they are comma separted values, google how to read csv lines). The first column represents your y values and the second column represents your x values. Make numpy arrays for y and x. Chose your naming convention of arrays as y and x only. (If you don't know how to read a file in python, google for it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conventional-alberta",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applicable-telling",
   "metadata": {},
   "source": [
    "The very first step to handle a dataset is to draw first-hand inferences as much as possible. Those inferences play a very vital role while actually desinging and deciding models. The first step to do so is to have plots and compute some statistics of the data. We will only do a plot, if you want you can do further analysis. Using matplotlib plot a scatterplot of the y values against the x values. (again google if you don't know how to do)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medium-upgrade",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considerable-customer",
   "metadata": {},
   "source": [
    "From the plot it seems that a linear fit to the available data is a plausible model (other than the fact that you haven't gone through other models yet :) ), so we have now decided we will perform a linear regression for the data using gradient descent. \\\n",
    "Let's have some revision...\\\n",
    "We have seen a sample cost function( we will use the same, but cost functions are very interesting, do try to think of some alternate cost functions too which can be good for linear fits )$$ J(\\theta) = \\frac{1}{2m}\\Sigma_{i=1}^{m}(h_\\theta(x^{(i)}) - y^{(i)})^2$$\n",
    "where $$ h_{\\theta}(x) = \\theta^{T}x = \\theta_0 + \\theta_1x_1$$\n",
    "\n",
    "So as an implementation we will have a 1x2 vector theta( numpy will come handy ) and since we already have x vector and y vector, it's actually quite simple to implement $J(\\theta)$.\n",
    "\n",
    "Now recall the update step of $\\theta$,\n",
    "$$\\theta_j = \\theta_j - \\alpha\\frac{1}{m}\\Sigma_{i=1}^{m}(h_\\theta(x^{(i)}) - y^{(i)})x_{j}^{(i)}$$\n",
    "So after choosing a parameter $\\alpha$ we are good to go. Keep in mind that the update has to be done for all $\\theta_j$s, you can do the simultaneous vectorized updates using numpy arrays.\n",
    "\n",
    "Ok enough theory, lets implement a function. \\\n",
    "Implement function **gradientdescent(y, x, theta, alpha)** that returns a list of size 2 - [updatedtheta, currentcost] . Note - The current cost is the cost calculated with the updated $\\theta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "increasing-travel",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradientdescent(y, x, theta, alpha)\n",
    "    #your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incoming-needle",
   "metadata": {},
   "source": [
    "Now it's time to call the function. Run for 1500 iterations (you can tweak it yourself too). Initialise your theta vector to [0,0] or you can even do randomly( will it matter? ). Take alpha to be 0.01( don't worry about tuning, you will know about it later ). Now run the loop and keep on updating theta and maintain an array where you keep on adding the cost values returned at each iteration. Store the final value of theta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "particular-submission",
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform iterations using the above function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empirical-aaron",
   "metadata": {},
   "source": [
    "Now it's time to analyse again. Using matplotlib, plot y vs x and on the same plot draw the line $y = \\theta_0 + \\theta_1x $ using the final theta values obtained. Also plot the curve of the cost array against the no. of the iterations. If you want you can further change alpha and no. of iterations to check how they affect the regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wicked-shepherd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot line and data together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electronic-japanese",
   "metadata": {},
   "source": [
    "You can see you have obtained a linear fit to the data. Welcome to Machine Learning.\n",
    "With the help of the trained theta we can estimate the values for x's for which y's have not been measured. The iteration you did to update theta is called the training. And the weights( in this case theta ) obtained after training, can be saved for use in applications, and definitely it's not as easy as this everytime. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sized-nursery",
   "metadata": {},
   "source": [
    "Let's get going. You implemented linear regression from scratch, let's now look at a fascinating python library - scikit-learn (imported as sklearn). Find installation procedure and official documentation here- https://scikit-learn.org/stable/ . Now perform a linear regression directly using scikit-learn and plot the line(using slope and intercept obtained in the model). Here you don't even have to worry about chosing hyperparameter alpha. Do check out other features of the library too. Hint -https://realpython.com/linear-regression-in-python/#simple-linear-regression-with-scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amateur-rocket",
   "metadata": {},
   "outputs": [],
   "source": [
    "#implement linear regression using sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pacific-extraction",
   "metadata": {},
   "source": [
    "As you proceed through the course, do check-out their equivalent models in scikit-learn."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
